{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "072c6e11-bb5d-4ea1-a607-87d52d8cbfff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "df = pd.read_csv(r\"C:\\Users\\Asus\\Downloads\\ML DATSETS\\Uber\\uber.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5d99626-4f5b-419f-ad36-9e07b9e78d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "笨 After removing NaN: 160,896\n",
      "笨 After fixing fare & passenger count: 160,896\n",
      "笨 After NYC geo-filter: 160,896\n",
      "笨 Added time features (hour, day of week)\n",
      "笨 After distance cleanup: 160,896\n"
     ]
    }
   ],
   "source": [
    "# --- 1) Pre-process ---\n",
    "df = df.dropna(subset=[\"fare_amount\",\"pickup_datetime\",\"pickup_longitude\",\"pickup_latitude\",\n",
    "                       \"dropoff_longitude\",\"dropoff_latitude\",\"passenger_count\"])\n",
    "print(f\"笨 After removing NaN: {len(df):,}\")\n",
    "\n",
    "df = df[(df.fare_amount > 0) & (df.fare_amount < 500)]\n",
    "df = df[(df.passenger_count >= 1) & (df.passenger_count <= 6)]\n",
    "print(f\"笨 After fixing fare & passenger count: {len(df):,}\")\n",
    "\n",
    "df = df[(df.pickup_latitude.between(40, 42)) &\n",
    "        (df.dropoff_latitude.between(40, 42)) &\n",
    "        (df.pickup_longitude.between(-75, -72)) &\n",
    "        (df.dropoff_longitude.between(-75, -72))]\n",
    "print(f\"笨 After NYC geo-filter: {len(df):,}\")\n",
    "\n",
    "# Time features\n",
    "dt = pd.to_datetime(df[\"pickup_datetime\"], errors=\"coerce\", utc=True)\n",
    "df = df[dt.notna()].copy()\n",
    "df[\"hour\"] = dt.dt.hour\n",
    "df[\"dow\"]  = dt.dt.dayofweek\n",
    "\n",
    "print(\"笨 Added time features (hour, day of week)\")\n",
    "\n",
    "# Distance calc (Haversine)\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    R = 6371.009\n",
    "    p1, p2 = np.radians(lat1), np.radians(lat2)\n",
    "    dphi  = np.radians(lat2-lat1)\n",
    "    dlmb  = np.radians(lon2-lon1)\n",
    "    a = np.sin(dphi/2)**2 + np.cos(p1)*np.cos(p2)*np.sin(dlmb/2)**2\n",
    "    return 2*R*np.arcsin(np.sqrt(a))\n",
    "\n",
    "df[\"dist_km\"] = haversine(df.pickup_latitude, df.pickup_longitude,\n",
    "                          df.dropoff_latitude, df.dropoff_longitude)\n",
    "\n",
    "df = df[(df.dist_km > 0) & (df.dist_km < 200)]\n",
    "print(f\"笨 After distance cleanup: {len(df):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c59a67bd-7410-488c-9e2e-9198a92dd494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "笨 Removed outliers in fare_amount: 1,642\n",
      "笨 Removed outliers in dist_km: 1,775\n",
      "沒 Final rows after cleaning: 157,479\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- 2) Outlier removal (IQR) ---\n",
    "for col in [\"fare_amount\",\"dist_km\"]:\n",
    "    q1, q3 = df[col].quantile([0.25, 0.75])\n",
    "    iqr = q3 - q1\n",
    "    low, high = q1 - 1.5*iqr, q3 + 1.5*iqr\n",
    "    before = len(df)\n",
    "    df = df[(df[col] >= low) & (df[col] <= high)]\n",
    "    print(f\"笨 Removed outliers in {col}: {before - len(df):,}\")\n",
    "\n",
    "print(f\"沒 Final rows after cleaning: {len(df):,}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed602e8f-348b-4467-b3bc-cfa1bc073e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "沒 CORRELATION WITH FARE:\n",
      " fare_amount          1.000000\n",
      "dist_km              0.773065\n",
      "hour                 0.019371\n",
      "passenger_count      0.018642\n",
      "dow                  0.006839\n",
      "dropoff_longitude    0.003664\n",
      "pickup_longitude    -0.023815\n",
      "pickup_latitude     -0.062108\n",
      "dropoff_latitude    -0.080450\n",
      "Name: fare_amount, dtype: float64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- 3) Correlation ---\n",
    "feat = [\"dist_km\",\"hour\",\"dow\",\"passenger_count\",\n",
    "        \"pickup_latitude\",\"pickup_longitude\",\"dropoff_latitude\",\"dropoff_longitude\"]\n",
    "\n",
    "corr = df[feat + [\"fare_amount\"]].corr()[\"fare_amount\"].sort_values(ascending=False)\n",
    "\n",
    "print(\"沒 CORRELATION WITH FARE:\\n\", corr, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40176681-0b3b-429d-96d2-f4f9d632d751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4) Split data ---\n",
    "X, y = df[feat], df[\"fare_amount\"]\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "lr = LinearRegression().fit(X_tr, y_tr)\n",
    "rf = RandomForestRegressor(n_estimators=300, n_jobs=-1, random_state=42).fit(X_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d3c7477-bb5d-49c2-8c0b-cd16bcfcb761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―n",
      "沒 Model: Linear Regression\n",
      "笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―n",
      "Rﾂｲ Score : 0.6026\n",
      "RMSE     : 1.924\n",
      "笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―n",
      "沒 Model: Random Forest\n",
      "笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―n",
      "Rﾂｲ Score : 0.6785\n",
      "RMSE     : 1.730\n"
     ]
    }
   ],
   "source": [
    "# --- 5) Evaluation ---\n",
    "def eval_model(name, mdl):\n",
    "    p = mdl.predict(X_te)\n",
    "    r2 = r2_score(y_te, p)\n",
    "    rmse = np.sqrt(mean_squared_error(y_te, p))  # 笨 works in all sklearn versions\n",
    "\n",
    "    print(\"笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―")\n",
    "    print(f\"沒 Model: {name}\")\n",
    "    print(\"笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―")\n",
    "    print(f\"Rﾂｲ Score : {r2:.4f}\")\n",
    "    print(f\"RMSE     : {rmse:.3f}\")\n",
    "\n",
    "eval_model(\"Linear Regression\", lr)\n",
    "eval_model(\"Random Forest\", rf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
